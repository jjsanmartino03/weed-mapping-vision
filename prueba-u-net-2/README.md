# U-Net Training Pipeline for Weed Detection in UAV Imagery

This repository contains a complete U-Net training pipeline for semantic segmentation of weeds in UAV agricultural imagery. The pipeline handles data download from Roboflow, YOLO polygon to mask conversion, dataset splitting, and U-Net model training.

## ğŸš€ Features

- **Automated Data Pipeline**: Downloads and processes data from Roboflow
- **YOLO to Mask Conversion**: Converts YOLO polygon annotations to binary masks
- **Data Augmentation**: Comprehensive augmentation pipeline using Albumentations
- **Advanced Loss Functions**: BCE + Dice Loss combination for better segmentation
- **Training Monitoring**: TensorBoard logging and visualization utilities
- **Model Checkpointing**: Automatic saving of best models based on validation metrics

## ğŸ“ Project Structure

```
prueba-u-net-2/
â”œâ”€â”€ train_unet.py          # Main training script
â”œâ”€â”€ unet_model.py          # U-Net model definition
â”œâ”€â”€ dataset.py             # PyTorch dataset and data loaders
â”œâ”€â”€ data_utils.py          # Data processing utilities
â”œâ”€â”€ losses.py              # Loss functions and metrics
â”œâ”€â”€ visualization.py       # Visualization utilities
â”œâ”€â”€ config.json           # Configuration file
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ README.md            # This file
```

## ğŸ› ï¸ Installation

1. **Clone the repository and navigate to the directory:**
   ```bash
   cd prueba-u-net-2
   ```

2. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

## ğŸ¯ Usage

### Basic Usage

Run the training pipeline with your Roboflow API key:

```bash
python train_unet.py --api_key YOUR_ROBOFLOW_API_KEY
```

### Advanced Usage

You can customize the training by modifying the `config.json` file or passing arguments:

```bash
python train_unet.py --api_key YOUR_API_KEY --config custom_config.json
```

### Configuration Options

The `config.json` file contains all training parameters:

- **Dataset Settings:**
  - `workspace`: Roboflow workspace name
  - `project`: Roboflow project name
  - `version`: Dataset version number
  - `train_ratio`: Training set proportion (default: 0.7)
  - `val_ratio`: Validation set proportion (default: 0.2)
  - `test_ratio`: Test set proportion (default: 0.1)

- **Training Settings:**
  - `batch_size`: Batch size for training (default: 4)
  - `num_epochs`: Number of training epochs (default: 50)
  - `learning_rate`: Initial learning rate (default: 1e-4)
  - `image_size`: Input image size [width, height] (default: [1024, 1024])

- **Model Settings:**
  - `bce_weight`: Weight for BCE loss (default: 0.5)
  - `dice_weight`: Weight for Dice loss (default: 0.5)
  - `bilinear`: Use bilinear upsampling (default: false)

## ğŸ“Š What the Pipeline Does

### 1. Data Download and Organization
- Downloads dataset from Roboflow in YOLOv8 segmentation format
- Automatically splits data into train/val/test sets
- Creates organized directory structure

### 2. YOLO to Mask Conversion
- Converts YOLO polygon annotations to binary masks
- Handles multiple polygons per image
- Saves masks as PNG files for efficient loading

### 3. Data Loading and Augmentation
- Implements PyTorch Dataset class for efficient data loading
- Applies comprehensive augmentations:
  - Geometric: Horizontal/vertical flips, rotations, scaling
  - Color: Brightness, contrast, saturation adjustments
  - Noise: Gaussian blur

### 4. Model Training
- U-Net architecture optimized for binary segmentation
- Combined BCE + Dice Loss for better performance
- Adam optimizer with learning rate scheduling
- Early stopping based on validation metrics

### 5. Monitoring and Visualization
- TensorBoard logging for training metrics
- Automatic saving of sample predictions
- Training history plots (loss, IoU, Dice score)
- Model checkpointing with best model selection

## ğŸ“ˆ Output Structure

After training, the following structure is created:

```
training_output/
â”œâ”€â”€ checkpoints/
â”‚   â”œâ”€â”€ best_model.pth           # Best model based on validation Dice
â”‚   â””â”€â”€ checkpoint_epoch_*.pth   # Regular checkpoints
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ training_history.png     # Training curves
â”‚   â”œâ”€â”€ training_metrics.json    # Numerical results
â”‚   â””â”€â”€ predictions_epoch_*.png  # Sample predictions
â”œâ”€â”€ tensorboard/                 # TensorBoard logs
â””â”€â”€ processed_dataset/           # Processed data
    â”œâ”€â”€ images/
    â”‚   â”œâ”€â”€ train/
    â”‚   â”œâ”€â”€ val/
    â”‚   â””â”€â”€ test/
    â””â”€â”€ masks/
        â”œâ”€â”€ train/
        â”œâ”€â”€ val/
        â””â”€â”€ test/
```

## ğŸ”§ Model Architecture

The U-Net model includes:
- **Encoder**: 4 downsampling blocks with skip connections
- **Decoder**: 4 upsampling blocks with concatenated features
- **Output**: Single channel for binary segmentation
- **Features**: Batch normalization, ReLU activation, dropout

## ğŸ“Š Metrics and Loss Functions

- **Loss Function**: Combined BCE + Dice Loss
- **Metrics**: IoU (Intersection over Union), Dice Coefficient
- **Evaluation**: Threshold-based binary classification metrics

## ğŸ›ï¸ Hyperparameters

Key hyperparameters and their defaults:
- Input size: 1024Ã—1024 pixels
- Batch size: 4 (adjust based on GPU memory)
- Learning rate: 1e-4 with ReduceLROnPlateau scheduling
- Weight decay: 1e-4
- Loss weights: BCE=0.5, Dice=0.5

## ğŸš¨ Requirements

- **Hardware**: GPU recommended (CUDA compatible)
- **Memory**: At least 8GB RAM, 6GB GPU memory for default settings
- **Python**: 3.8+
- **Key Dependencies**: PyTorch, OpenCV, Albumentations, Roboflow

## ğŸ” Troubleshooting

**Common Issues:**

1. **Out of Memory**: Reduce batch_size in config.json
2. **Slow Training**: Reduce image_size or use more num_workers
3. **Poor Performance**: Increase num_epochs or adjust loss weights
4. **Data Download Issues**: Check your Roboflow API key and internet connection

## ğŸ“ Example Results

The pipeline automatically generates:
- Training curves showing loss and metric progression
- Sample predictions comparing ground truth vs model output
- Comprehensive metrics logging via TensorBoard
- Best model selection based on validation performance

## ğŸ¤ Contributing

Feel free to contribute by:
- Reporting bugs or issues
- Suggesting improvements
- Adding new features
- Improving documentation

## ğŸ“„ License

This project is available for academic and research purposes. 